{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "\n",
    "# Load the MNIST data for this exercise\n",
    "# mat_data contain the training and testing images or labels.\n",
    "#   Each matrix has size [m,n] for images where:\n",
    "#      m is the number of examples.\n",
    "#      n is the number of pixels in each image.\n",
    "#   or Each matrix has size [m,1] for labels contain the corresponding labels (0 to 9) where:\n",
    "#      m is the number of examples.\n",
    "def load_mnist(file_dir, is_images='True'):\n",
    "    # Read binary data\n",
    "    bin_file = open(file_dir, 'rb')\n",
    "    bin_data = bin_file.read()\n",
    "    bin_file.close()\n",
    "    # Analysis file header\n",
    "    if is_images:\n",
    "        # Read images\n",
    "        fmt_header = '>iiii'\n",
    "        magic, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, 0)\n",
    "    else:\n",
    "        # Read labels\n",
    "        fmt_header = '>ii'\n",
    "        magic, num_images = struct.unpack_from(fmt_header, bin_data, 0)\n",
    "        num_rows, num_cols = 1, 1\n",
    "    data_size = num_images * num_rows * num_cols\n",
    "    mat_data = struct.unpack_from('>' + str(data_size) + 'B', bin_data, struct.calcsize(fmt_header))\n",
    "    mat_data = np.reshape(mat_data, [num_images, num_rows * num_cols])\n",
    "    print('Load images from %s, number: %d, data shape: %s' % (file_dir, num_images, str(mat_data.shape)))\n",
    "    return mat_data\n",
    "\n",
    "# tranfer the image from gray to binary and get the one-hot style labels\n",
    "def data_convert(x, y, m, k):\n",
    "    x[x<=40]=0\n",
    "    x[x>40]=1\n",
    "    ont_hot_y = np.zeros((m,k))    #(60000,10)\n",
    "    for t in np.arange(0,m):\n",
    "        ont_hot_y[t,y[t]]=1\n",
    "    ont_hot_y=ont_hot_y.T #(10,60000)\n",
    "    return x, ont_hot_y\n",
    "\n",
    "# call the load_mnist function to get the images and labels of training set and testing set\n",
    "def load_data(mnist_dir, train_data_dir, train_label_dir, test_data_dir, test_label_dir):\n",
    "    print('Loading MNIST data from files...')\n",
    "    \n",
    "    print(os.path.join(mnist_dir, train_data_dir))\n",
    "    train_images = load_mnist(os.path.join(mnist_dir, train_data_dir), True)\n",
    "    train_labels = load_mnist(os.path.join(mnist_dir, train_label_dir), False)\n",
    "    test_images = load_mnist(os.path.join(mnist_dir, test_data_dir), True)\n",
    "    test_labels = load_mnist(os.path.join(mnist_dir, test_label_dir), False)\n",
    "    return train_images, train_labels, test_images, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dir = \"./mnist_data/\"\n",
    "train_data_dir = \"train-images.idx3-ubyte\"\n",
    "train_label_dir = \"train-labels.idx1-ubyte\"\n",
    "test_data_dir = \"t10k-images.idx3-ubyte\"\n",
    "test_label_dir = \"t10k-labels.idx1-ubyte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data from files...\n",
      "./mnist_data/train-images.idx3-ubyte\n",
      "Load images from ./mnist_data/train-images.idx3-ubyte, number: 60000, data shape: (60000, 784)\n",
      "Load images from ./mnist_data/train-labels.idx1-ubyte, number: 60000, data shape: (60000, 1)\n",
      "Load images from ./mnist_data/t10k-images.idx3-ubyte, number: 10000, data shape: (10000, 784)\n",
      "Load images from ./mnist_data/t10k-labels.idx1-ubyte, number: 10000, data shape: (10000, 1)\n",
      "Got data. \n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, test_images, test_labels = load_data(mnist_dir, train_data_dir, train_label_dir, test_data_dir, test_label_dir)\n",
    "print(\"Got data. \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(len(test_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    img = np.reshape(train_images [i, :], (28, 28))\n",
    "    label = np.argmax(train_images [i, :])\n",
    "    plt.matshow(img, cmap = plt.get_cmap('gray'))\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self, in_channels, out_channels, filter_size, stride=1, padding=0):\n",
    "        \"\"\"\n",
    "        params: in_channels: the number of channels of the input image\n",
    "                out_channels: the number of channels of the output image\n",
    "                filter_size:(x,y) the size of the filter\n",
    "                stride: the stride of the filter\n",
    "                padding: the padding of the filter\n",
    "        \"\"\"\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.Weight = np.random.normal(scale=1, size=(out_channels,in_channels,filter_size[0],filter_size[1]))\n",
    "        #第一个维度是输出通道数，对应着有这么多个卷积核；第二个维度是输入通道数，这是因为卷积核需要负责讲in个channel的输入变成out个channel的输出\n",
    "\n",
    "        self.W_grad = None\n",
    "        self.Bias = np.zeros(out_channels) #每个卷积核有一个偏置参数\n",
    "        self.B_grad = None\n",
    "    \n",
    "    def Conv2D(self):\n",
    "        # def conv(x,y,i,j): #从(x,y)到(x+filter_size,t+filter_size)的input与weight[i,j]的卷积计算\n",
    "        #     return np.sum(X[x:x+self.filter_size,y:y+self.filter_size] * self.Weight[i,j])\n",
    "        \n",
    "        # res = []\n",
    "        # for i in range(self.in_channels):\n",
    "        #     for o in range(self.out_channels):\n",
    "        #         res.extend(joblib.Parallel(n_jobs=-1,verbose=0)(joblib.delayed(conv)(h*self.stride,w*self.stride,i,o) for h in range(self.output_H) for w in range(self.output_W) ))\n",
    "        # return np.array(res).reshape(self.in_channels,self.out_channels,self.output_H,self.output_W)\n",
    "        for i in range(self.in_channels):\n",
    "            for o in range(self.out_channels):\n",
    "                for h in range(self.output_H):\n",
    "                    for w in range(self.output_W):\n",
    "                        self.output[i,o,h,w] = np.sum(self.input[h*self.stride:h*self.stride+self.filter_size[0],\n",
    "                                                                 w*self.stride:w*self.stride+self.filter_size[1]] * self.Weight[i,o])\n",
    "                \n",
    "    def forward(self, X):\n",
    "        C,W,H = X.shape  \n",
    "        # C for Channels, W for Width, H for Height\n",
    "\n",
    "        # 进行padding操作，填充0\n",
    "        if self.padding!= 0:\n",
    "            for channels in range(C):\n",
    "                X[channels] = np.pad(X[channels], ((self.padding, self.padding), (self.padding, self.padding)),\n",
    "                                     'constant',constant_values = (0,0))\n",
    "            \n",
    "        output_W = (W + 2*self.padding - self.filter_size[0]) // self.stride + 1\n",
    "        output_W = int(output_W)\n",
    "        output_H = (H + 2*self.padding - self.filter_size[1]) // self.stride + 1\n",
    "        output_H = int(output_H)\n",
    "        self.output = np.zeros((self.out_channels, output_H, output_W))\n",
    "        \n",
    "        for o in range(self.out_channels):\n",
    "                for h in range(output_H):\n",
    "                    for w in range(output_W):\n",
    "                        self.output[o,h,w] = np.sum(X[:,h*self.stride:h*self.stride+self.filter_size[0],\n",
    "                                                                 w*self.stride:w*self.stride+self.filter_size[1]] * self.Weight[o])+self.Bias[o]\n",
    "        return self.output\n",
    "    \n",
    "    def backprop(self, dout):\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(size = (3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool:\n",
    "    def __init__(self,pool_size=None,stride = 1):\n",
    "        if pool_size is None:\n",
    "            pool_size = [2, 2]\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.output = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        in_channels,h,w = X.shape\n",
    "        output_h = h // self.pool_size[0]\n",
    "        output_w = w // self.pool_size[1]\n",
    "        self.output = np.zeros((in_channels,output_h,output_w))\n",
    "        for i in range(output_h):\n",
    "            for j in range(output_w):\n",
    "                self.output[:,i,j] = np.max(X[:, i*self.pool_size[0]:(i+1)*self.pool_size[0], j*self.pool_size[1]:(j+1)*self.pool_size[1]], axis=(1, 2))\n",
    "        return self.output\n",
    "    \n",
    "    def backprop(self, back_grad):\n",
    "        pass\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self,input_size,output_size) :\n",
    "        self.Weight = np.random.normal(scale=1, size=(input_size, output_size))\n",
    "        self.W_grad = None\n",
    "        self.Bias = np.zeros(output_size)\n",
    "        self.B_grad = None\n",
    "    \n",
    "    def forward(self,X):\n",
    "        return np.dot(X,self.Weight) + self.Bias\n",
    "    \n",
    "    def back_prop(self,back_grad):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = Conv(1, 6, (5,5))\n",
    "\n",
    "test = test.reshape(1,28,28)\n",
    "x = C1.forward(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 26, 26)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ReLu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 24, 24)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = MaxPool((2,2))\n",
    "x = S2.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 12, 12)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "C3 = Conv(6,16,(5,5))\n",
    "x = C3.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ReLu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "S4 = MaxPool((2,2))\n",
    "x = S4.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4, 4)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "C5 = Linear(16*4*4,120)\n",
    "x1 = C5.forward(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "F6 = Linear(120,84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = F6.forward(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Linear(84,10)\n",
    "x1 = output.forward(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(scale=1, size=(1,6,5,5))\n",
    "d = np.random.normal(scale=1,size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.random.normal(scale=1,size=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2D():\n",
    "        def conv(x,y,i,j): #从(x,y)到(x+filter_size,t+filter_size)的input与weight[i,j]的卷积计算\n",
    "            return np.sum(t[x:x+5,y:y+5] * a[i,j])\n",
    "        \n",
    "     \n",
    "        res = (joblib.Parallel(n_jobs=-1,verbose=0)(joblib.delayed(conv)(h,w,i,o)for i in range(1) for o in range(6) for h in range(24) for w in range(24) ))\n",
    "        return np.array(res).reshape(1,6,24,24)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros(shape=(1,6,24,24))\n",
    "for i in range(1):\n",
    "    for j in range(6):\n",
    "        for k in range(24):\n",
    "            for l in range(24):\n",
    "                b[i][j][k][l] = np.sum(t[k:k+5,l:l+5] * a[i,j])+d[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "input_matrix = np.random.rand(28, 28)\n",
    "convolution_kernel = np.random.rand(5, 5)\n",
    "\n",
    "result = convolve2d(t, a[0,1], mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121.53240548251058"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.38186510590201"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Conv2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.38186510590201"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.93313814, -24.53926697,  -1.97669086,  35.7300471 ,\n",
       "        22.27250686,  -0.64002107, -25.22907756, -23.95069935,\n",
       "        -5.53545181,   4.35950017,  13.34553573,  23.17592675,\n",
       "        -3.65901826, -30.33391001, -33.09603435,   6.08068901,\n",
       "        36.29357402,  10.10776773,   4.87682599,  -9.26808911,\n",
       "         7.09052633,   5.54335861,  -9.90899801,  -2.95640318])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(b[0,1] - result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34859123,  0.06920816,  2.27276008,  0.23363653,  0.22236938],\n",
       "       [ 0.12490571,  1.29480527, -0.50622616, -1.66978477,  0.21479421],\n",
       "       [-1.31754901, -1.13363826,  1.61447842,  0.3093921 ,  0.83311412],\n",
       "       [-0.12174634,  1.71252122, -0.40290676,  1.70859997,  0.19225454],\n",
       "       [-0.73175619, -0.73192317, -0.83354696,  0.8423247 ,  0.18075662]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.20685966e-01,  1.92357766e-01, -6.75320741e-01,\n",
       "        -5.50791318e-01,  1.25817385e+00],\n",
       "       [ 4.39842884e-01, -1.00497408e+00,  7.82645803e-01,\n",
       "        -3.32227220e-01,  1.24518928e+00],\n",
       "       [-1.48506636e+00, -1.74401920e+00,  6.14466219e-01,\n",
       "         1.01814999e+00, -1.90725948e+00],\n",
       "       [-1.43050082e-01, -5.42540574e-01,  1.89386318e+00,\n",
       "         4.71446098e-01, -2.75087901e-01],\n",
       "       [ 7.34852903e-01, -1.31681826e+00,  2.49603101e+00,\n",
       "         1.33807771e+00, -1.42505639e-03]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.20685966e-01,  1.92357766e-01, -6.75320741e-01,\n",
       "        -5.50791318e-01,  1.25817385e+00],\n",
       "       [ 4.39842884e-01, -1.00497408e+00,  7.82645803e-01,\n",
       "        -3.32227220e-01,  1.24518928e+00],\n",
       "       [-1.48506636e+00, -1.74401920e+00,  6.14466219e-01,\n",
       "         1.01814999e+00, -1.90725948e+00],\n",
       "       [-1.43050082e-01, -5.42540574e-01,  1.89386318e+00,\n",
       "         4.71446098e-01, -2.75087901e-01],\n",
       "       [ 7.34852903e-01, -1.31681826e+00,  2.49603101e+00,\n",
       "         1.33807771e+00, -1.42505639e-03]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43984288, -1.00497408],\n",
       "       [-1.48506636, -1.7440192 ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,2,1:3,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "]\n",
    "b = np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1578606973703502"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a[0,2,:2,:2] * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  16 | elapsed:    1.0s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  16 | elapsed:    1.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "def conv(x,y):\n",
    "    return np.sum(a[0,2,x:x+2,y:y+2] * b)\n",
    "res = joblib.Parallel(n_jobs=-1,verbose=2)(joblib.delayed(conv)(x,y) for x in range(5-2+1) for y in range(5-2+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.1578606973703502,\n",
       " 2.6552983914667734,\n",
       " -1.2394024457623216,\n",
       " -0.2315486671161362,\n",
       " 1.1858641247199175,\n",
       " 0.570865537147406,\n",
       " 1.5185567974674905,\n",
       " -4.502825976596664,\n",
       " -0.14053765221159542,\n",
       " 0.07791833080551491,\n",
       " -1.8261008551351605,\n",
       " 2.1788754736839815,\n",
       " -1.6521806703091342,\n",
       " 1.376445515390394,\n",
       " 0.26446378283225935,\n",
       " -0.5929687680394632]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.1578607 ,  2.65529839, -1.23940245, -0.23154867],\n",
       "       [ 1.18586412,  0.57086554,  1.5185568 , -4.50282598],\n",
       "       [-0.14053765,  0.07791833, -1.82610086,  2.17887547],\n",
       "       [-1.65218067,  1.37644552,  0.26446378, -0.59296877]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res).reshape(4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LeNet import LeNet\n",
    "from data_process import load_data,data_convert\n",
    "from evaluate import softmax,cal_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dir = \"./mnist_data/\"\n",
    "train_data_dir = \"train-images.idx3-ubyte\"\n",
    "train_label_dir = \"train-labels.idx1-ubyte\"\n",
    "test_data_dir = \"t10k-images.idx3-ubyte\"\n",
    "test_label_dir = \"t10k-labels.idx1-ubyte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data from files...\n",
      "./mnist_data/train-images.idx3-ubyte\n",
      "Load images from ./mnist_data/train-images.idx3-ubyte, number: 60000, data shape: (60000, 784)\n",
      "Load images from ./mnist_data/train-labels.idx1-ubyte, number: 60000, data shape: (60000, 1)\n",
      "Load images from ./mnist_data/t10k-images.idx3-ubyte, number: 10000, data shape: (10000, 784)\n",
      "Load images from ./mnist_data/t10k-labels.idx1-ubyte, number: 10000, data shape: (10000, 1)\n",
      "Got data. \n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, test_images, test_labels = load_data(mnist_dir, train_data_dir, train_label_dir, test_data_dir, test_label_dir)\n",
    "print(\"Got data. \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    img = np.reshape(train_images [i, :], (28, 28))\n",
    "    label = np.argmax(train_images [i, :])\n",
    "    plt.matshow(img, cmap = plt.get_cmap('gray'))\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data_convert(train_images, train_labels,60000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(batch_size):\n",
    "\n",
    "    index = np.random.randint(0,len(x),batch_size)\n",
    "    return x[index],y.T[index].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(params,x_val,y_val):\n",
    "    model = LeNet()\n",
    "    model.set_params(params)\n",
    "    y_pred = model.fit(x_val,x_val.shape[0])\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    # TODO: Compute the accuracy among the test set and store it in acc\n",
    "    y_val=y_val.reshape(len(y_val))\n",
    "    res = y_pred-y_val    #相减，相同的项相减后为0\n",
    "    incorrect = np.count_nonzero(res)   #计算有多少个不为0的项，即y_pred和y不相同的项的个数\n",
    "    acc = 1-incorrect/len(y_val)         #计算正确率\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = cal_accuracy(model,test_images[0:1000],test_labels[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10799999999999998"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.fit(x[0:500],500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18109420.93518278"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,grad,y_pred = softmax(y_pred,y[:,0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 84)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Output.input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.back_prop(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = shuffle_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 784)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.fit(X_train,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, grad, y_pred = softmax(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.296080310884536"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -311038.26092776,  2347997.88797649, -2974666.4590697 , ...,\n",
       "         5313881.22390467, -1448695.98336833, -3506334.66723409],\n",
       "       [ -758438.50679917,  4092248.24306851, -4572812.96937503, ...,\n",
       "         3992572.43368527,  -453619.59396196, -3663667.28934029],\n",
       "       [-3473010.34364727,  5395064.43221974, -3528840.92945717, ...,\n",
       "         1462421.31534039, -1940125.20047131, -2705539.86555242],\n",
       "       ...,\n",
       "       [  559300.09698867,  3857175.45142322, -6556484.41845315, ...,\n",
       "         7009696.7194365 ,  -842266.61207645, -6413441.87842566],\n",
       "       [-2857349.19972392,  5163445.26056176, -6140983.65689367, ...,\n",
       "         5135980.56540975, -1590087.40999815,  -781562.56580953],\n",
       "       [ 1360533.60968179,  1731876.33502661,   680191.8657714 , ...,\n",
       "         5275267.33554773, -2118652.76435024, -1849100.40695828]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(test_images[0:1000],1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = shuffle_batch(batch_size)\n",
    "y_pred = model.fit(X_train,batch_size)\n",
    "\n",
    "loss, grad, y_pred = softmax(y_pred, y_train)\n",
    "model.back_prop(grad)\n",
    "model.update(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = shuffle_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = LeNet5()\n",
    "test1 = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.86463489e-12,  4.84332626e-12, -1.15880767e-11, ...,\n",
       "        -2.62081587e-11,  3.42113586e-11,  9.51039950e-12],\n",
       "       [ 1.21048123e-11,  2.07958146e-12, -8.72917644e-12, ...,\n",
       "        -2.31779807e-11,  1.35778951e-11,  3.66870632e-12],\n",
       "       [ 1.50951152e-11,  1.85397744e-12, -2.43616250e-11, ...,\n",
       "        -3.49754897e-11,  2.95744043e-11, -5.33663434e-12],\n",
       "       ...,\n",
       "       [ 1.81419571e-11, -1.07726864e-11, -8.94751678e-12, ...,\n",
       "        -3.65070293e-11,  2.81650830e-11,  2.83181743e-11],\n",
       "       [ 6.49723682e-12,  5.89989282e-13, -9.60876514e-12, ...,\n",
       "        -1.40868091e-11,  2.50974280e-11,  1.24962576e-11],\n",
       "       [ 1.08262102e-11,  1.54681872e-11, -2.49178731e-11, ...,\n",
       "        -4.12261834e-11,  2.76279702e-11,  7.06280136e-12]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.forward(X_train.reshape(batch_size,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get\n"
     ]
    }
   ],
   "source": [
    "test1.set_params(test.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.86463489e-12,  4.84332626e-12, -1.15880767e-11, ...,\n",
       "        -2.62081587e-11,  3.42113586e-11,  9.51039950e-12],\n",
       "       [ 1.21048123e-11,  2.07958146e-12, -8.72917644e-12, ...,\n",
       "        -2.31779807e-11,  1.35778951e-11,  3.66870632e-12],\n",
       "       [ 1.50951152e-11,  1.85397744e-12, -2.43616250e-11, ...,\n",
       "        -3.49754897e-11,  2.95744043e-11, -5.33663434e-12],\n",
       "       ...,\n",
       "       [ 1.81419571e-11, -1.07726864e-11, -8.94751678e-12, ...,\n",
       "        -3.65070293e-11,  2.81650830e-11,  2.83181743e-11],\n",
       "       [ 6.49723682e-12,  5.89989282e-13, -9.60876514e-12, ...,\n",
       "        -1.40868091e-11,  2.50974280e-11,  1.24962576e-11],\n",
       "       [ 1.08262102e-11,  1.54681872e-11, -2.49178731e-11, ...,\n",
       "        -4.12261834e-11,  2.76279702e-11,  7.06280136e-12]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.fit(X_train,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = test1.fit(X_train,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11493.5363824 ,  25461.11848911,  14904.68775691, ...,\n",
       "          6208.57045711, -13391.94105291,  23778.64055244],\n",
       "       [  5109.38427061,  24979.63484023,   5357.09949956, ...,\n",
       "         -9106.51029215,  -6597.68246864,  30087.41446535],\n",
       "       [ 10427.09133908,  18355.39163483,  12541.82215144, ...,\n",
       "          8359.48601334, -15055.07925902,  29390.6863899 ],\n",
       "       ...,\n",
       "       [ 28533.82198856,  22153.44759396,  13839.07520864, ...,\n",
       "          3781.66221755, -22845.75581953,  37344.15831072],\n",
       "       [ 17578.66646593,   9612.40138327,   9372.31154885, ...,\n",
       "         -2378.65114922, -16464.27826381,  25525.14221269],\n",
       "       [-11683.7889507 ,  31807.87485058,  22716.97984874, ...,\n",
       "         -2773.98723976, -29644.3436814 ,  23438.2849941 ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred += 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        2.55877435e-90, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred - y_pred.max(axis=1)[:,None] #防止溢出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, grad, acc = softmax(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, grad, acc = softmax_loss(y_pred, y_train.argmax(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025850929926275"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00039063, -0.00351562,  0.00039062, ...,  0.00039062,\n",
       "         0.00039063,  0.00039063],\n",
       "       [ 0.00039063, -0.00351563,  0.00039062, ...,  0.00039062,\n",
       "         0.00039063,  0.00039063],\n",
       "       [ 0.00039063,  0.00039063,  0.00039062, ...,  0.00039062,\n",
       "         0.00039063,  0.00039062],\n",
       "       ...,\n",
       "       [ 0.00039063,  0.00039062, -0.00351563, ...,  0.00039062,\n",
       "         0.00039063,  0.00039063],\n",
       "       [ 0.00039063, -0.00351563,  0.00039062, ...,  0.00039062,\n",
       "         0.00039063,  0.00039063],\n",
       "       [ 0.00039063,  0.00039063,  0.00039062, ...,  0.00039062,\n",
       "         0.00039063,  0.00039063]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad1 = grad/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00039062,  0.00039062,  0.00039063, ...,  0.00039062,\n",
       "         0.00039062,  0.00039063],\n",
       "       [-0.00351563,  0.00039062,  0.00039062, ...,  0.00039062,\n",
       "         0.00039062,  0.00039063],\n",
       "       [ 0.00039062,  0.00039062,  0.00039062, ...,  0.00039062,\n",
       "         0.00039062,  0.00039063],\n",
       "       ...,\n",
       "       [ 0.00039062,  0.00039062,  0.00039062, ...,  0.00039062,\n",
       "         0.00039062,  0.00039063],\n",
       "       [-0.00351562,  0.00039062,  0.00039063, ...,  0.00039062,\n",
       "         0.00039062,  0.00039063],\n",
       "       [ 0.00039062,  0.00039062,  0.00039062, ...,  0.00039062,\n",
       "        -0.00351563,  0.00039063]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.back_prop(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = cal_accuracy(model.get_params(),test_images[0:1000],test_labels[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09899999999999998"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y_pred,y):\n",
    "    batch_size ,_ = y_pred.shape\n",
    "    y_pred = y_pred / y_pred.max(axis=1)[:,None] #防止溢出\n",
    "    y_pred +=1e-5\n",
    "    y_pred = np.exp(y_pred)\n",
    "    y_sum = y_pred.sum(axis = 1)\n",
    "    y_pred = y_pred/y_sum[:,None]\n",
    "    loss = -np.log(y_pred).T * y\n",
    "    loss = loss.sum()/batch_size\n",
    "    grad = y_pred - y.T\n",
    "    grad /= batch_size\n",
    "    acc = (y_pred.argmax(axis=1) == y.argmax(axis=0)).mean()\n",
    "    return loss,grad,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(y_pred, y):\n",
    "    # y_pred: (N, C)\n",
    "    # y: (N, 1)\n",
    "    N = y_pred.shape[0]\n",
    "    ex = np.exp(y_pred)\n",
    "    sumx = np.sum(ex, axis=1)\n",
    "    loss = np.mean(np.log(sumx)-y_pred[range(N), list(y)])\n",
    "    grad = ex/sumx.reshape(N, 1)\n",
    "    grad[range(N), list(y)] -= 1\n",
    "    grad /= N\n",
    "    acc = np.mean(np.argmax(ex/sumx.reshape(N, 1), axis=1) == y.reshape(1, y.shape[0]))\n",
    "    return loss, grad, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1171875"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred.argmax(axis=1) == y_train.argmax(axis=0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,grad,_ = softmax(y_pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3106604049807493"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3183898417423734e-15"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,grad,_ = softmax_loss(y_pred,y_train.argmax(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2982749070385187"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.149960319306146e-18"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(range(0, int(x.shape[0]/batch_size)), ncols=100)\n",
    "for i in pbar:\n",
    "    X_train,y_train = shuffle_batch(batch_size)\n",
    "    y_pred = model.fit(X_train,batch_size)\n",
    "\n",
    "    loss, grad, acc = softmax(y_pred, y_train)\n",
    "    model.back_prop(grad)\n",
    "    model.update(0.1)\n",
    "    pbar.set_postfix(loss=loss, acc=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(model,x_val,y_val):\n",
    "    y_pred = model.fit(x_val,x_val.shape[0])\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    # TODO: Compute the accuracy among the test set and store it in acc\n",
    "    y_val=y_val.reshape(len(y_val))\n",
    "    res = y_pred-y_val    #相减，相同的项相减后为0\n",
    "    incorrect = np.count_nonzero(res)   #计算有多少个不为0的项，即y_pred和y不相同的项的个数\n",
    "    acc = 1-incorrect/len(y_val)         #计算正确率\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = shuffle_batch(batch_size)\n",
    "y_pred = model.fit(X_train,batch_size)\n",
    "\n",
    "loss, grad, y_pred = softmax(y_pred, y_train)\n",
    "#acc = cal_accuracy(model,test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.397517375194011"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = cal_accuracy(model,test_images[:1000],test_labels[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15200000000000002"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, model, lr=1e-3, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.model = model\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.params = None\n",
    "        self.grad = None\n",
    "\n",
    "    def step(self):\n",
    "        self.params = model.get_params()\n",
    "        self.grad = model.get_grad()\n",
    "        if self.m is None:\n",
    "            self.m, self.v = [], []\n",
    "            for param in self.params:\n",
    "                self.m.append(np.zeros_like(param))\n",
    "            for g in self.grad:\n",
    "                self.v.append(np.zeros_like(g))\n",
    "            assert(len(self.m) == len(self.params))\n",
    "            assert(len(self.v) == len(self.grad))\n",
    "\n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2 ** self.iter) / (1.0 - self.beta1 ** self.iter)\n",
    "\n",
    "        for i in range(len(self.params)):\n",
    "            self.m[i] += (1 - self.beta1) * (self.grad[i] - self.m[i])\n",
    "            self.v[i] += (1 - self.beta2) * (self.grad[i] ** 2 - self.v[i])\n",
    "            self.params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam1:\n",
    "    def __init__(self, params, lr=1e-3, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.params_grad = params\n",
    "\n",
    "    def step(self):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = [], []\n",
    "            for param in self.params_grad:\n",
    "                self.m.append(np.zeros_like(param['value']))\n",
    "                self.v.append(np.zeros_like(param['grad']))\n",
    "\n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2 ** self.iter) / (1.0 - self.beta1 ** self.iter)\n",
    "\n",
    "        for i in range(len(self.params_grad)):\n",
    "            self.m[i] += (1 - self.beta1) * (self.params_grad[i]['grad'] - self.m[i])\n",
    "            self.v[i] += (1 - self.beta2) * (self.params_grad[i]['grad'] ** 2 - self.v[i])\n",
    "            self.params_grad[i]['value'] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "\n",
    "model = LeNet()\n",
    "optimizer = Adam(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = shuffle_batch(batch_size)\n",
    "y_pred = model.fit(X_train,batch_size)\n",
    "\n",
    "loss, grad, acc = softmax(y_pred, y_train)\n",
    "model.back_prop(grad)\n",
    "#model.update(0.001)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▍                                  | 32/234 [00:31<03:18,  1.02it/s, acc=0.449, loss=1.78]C:\\Users\\zxy08\\AppData\\Local\\Temp\\ipykernel_13528\\2231349577.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.log(y_pred).T * y\n",
      "C:\\Users\\zxy08\\AppData\\Local\\Temp\\ipykernel_13528\\2231349577.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.log(y_pred).T * y\n",
      " 14%|█████▉                                    | 33/234 [00:33<03:21,  1.00s/it, acc=0.52, loss=nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train,batch_size)\n\u001b[0;32m     12\u001b[0m loss, grad, acc \u001b[38;5;241m=\u001b[39m softmax(y_pred, y_train)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mback_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#model.update(0.001)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\CODE\\machine-learning\\LeNet5\\LeNet.py:40\u001b[0m, in \u001b[0;36mLeNet.back_prop\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m     38\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPool1\u001b[38;5;241m.\u001b[39mbackprop(grad)\n\u001b[0;32m     39\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRelu1\u001b[38;5;241m.\u001b[39mbackprop(grad)\n\u001b[1;32m---> 40\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CODE\\machine-learning\\LeNet5\\layers.py:77\u001b[0m, in \u001b[0;36mConv.backprop\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m     75\u001b[0m reverse_kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWeight\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     76\u001b[0m reverse_kernel  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflip(reverse_kernel,axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m---> 77\u001b[0m grad_next \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreverse_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_size\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mBias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWeight)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output_H):\n",
      "File \u001b[1;32md:\\CODE\\machine-learning\\LeNet5\\layers.py:58\u001b[0m, in \u001b[0;36mConv.conv2d\u001b[1;34m(self, input, kernel, padding, Bias)\u001b[0m\n\u001b[0;32m     56\u001b[0m w_end \u001b[38;5;241m=\u001b[39m w_start \u001b[38;5;241m+\u001b[39m filter_size\n\u001b[0;32m     57\u001b[0m input_region \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[:, :, h_start:h_end, w_start:w_end]\u001b[38;5;241m.\u001b[39mreshape((N, \u001b[38;5;241m1\u001b[39m, C, filter_size, filter_size))\n\u001b[1;32m---> 58\u001b[0m output_matrix[:, :, h, w] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_region\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     output_matrix[:, :, h, w] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBias\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:2183\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2114\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[0;32m   2115\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2178\u001b[0m \n\u001b[0;32m   2179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 2183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2184\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2190\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "\n",
    "model = LeNet()\n",
    "optimizer = Adam(model,0.2)\n",
    "for e in range(10):\n",
    "    pbar = tqdm(range(0, int(x.shape[0]/batch_size)), ncols=100)\n",
    "    for i in pbar:\n",
    "        X_train,y_train = shuffle_batch(batch_size)\n",
    "        y_pred = model.fit(X_train,batch_size)\n",
    "\n",
    "        loss, grad, acc = softmax(y_pred, y_train)\n",
    "        model.back_prop(grad)\n",
    "        #model.update(0.001)\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=loss, acc=acc)\n",
    "\n",
    "# val_X = data[\"X_val\"]\n",
    "# val_y = data[\"y_val\"]\n",
    "# y_pred = model.forward(val_X)\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "# acc = np.mean(y_pred == val_y.reshape(1, val_y.shape[0]))\n",
    "# if acc > best_acc:\n",
    "#     best_acc = acc\n",
    "#     best_weight = model.get_params()\n",
    "# pbar.set_postfix(val_acc=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████▎                     | 104/234 [01:13<01:31,  1.42it/s, acc=0.109, loss=2.33]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#loss, grad, acc = softmax_loss(y_pred, y_train.argmax(axis=0))\u001b[39;00m\n\u001b[0;32m     15\u001b[0m loss, grad, acc \u001b[38;5;241m=\u001b[39m softmax(y_pred, y_train)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#model.update(0.5)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m optimizer1\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\CODE\\machine-learning\\LeNet5\\model.py:43\u001b[0m, in \u001b[0;36mLeNet5.backward\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m     41\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2\u001b[38;5;241m.\u001b[39mbackward(grad)\n\u001b[0;32m     42\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2\u001b[38;5;241m.\u001b[39mbackward(grad)\n\u001b[1;32m---> 43\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1\u001b[38;5;241m.\u001b[39mbackward(grad)\n\u001b[0;32m     45\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1\u001b[38;5;241m.\u001b[39mbackward(grad)\n",
      "File \u001b[1;32md:\\CODE\\machine-learning\\LeNet5\\layer.py:134\u001b[0m, in \u001b[0;36mConv.backward\u001b[1;34m(self, back_grad)\u001b[0m\n\u001b[0;32m    132\u001b[0m tmp_back_grad \u001b[38;5;241m=\u001b[39m back_grad[:, :, h, w]\u001b[38;5;241m.\u001b[39mreshape((N, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels))\n\u001b[0;32m    133\u001b[0m tmp_W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels))\n\u001b[1;32m--> 134\u001b[0m grad[:, :, h \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride:h \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_size, w \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride:w \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_size] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_back_grad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtmp_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m tmp_back_grad \u001b[38;5;241m=\u001b[39m back_grad[:, :, h, w]\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, N))\n\u001b[0;32m    136\u001b[0m tmp_x \u001b[38;5;241m=\u001b[39m padding_x[:, :, h \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride:h \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_size, w \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride:w \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_size]\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:2183\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2114\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[0;32m   2115\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2178\u001b[0m \n\u001b[0;32m   2179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 2183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2184\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2190\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = LeNet5()\n",
    "batch_size = 256\n",
    "epochs = 1\n",
    "lr = 0.75\n",
    "\n",
    "optimizer1 = Adam1(model1.get(), lr)\n",
    "\n",
    "for e in range(10):\n",
    "        # add tqdm\n",
    "        pbar = tqdm(range(0, int(x.shape[0]/batch_size)), ncols=100)\n",
    "        for i in pbar:\n",
    "            X_train,y_train = shuffle_batch(batch_size)\n",
    "            y_pred = model1.forward(X_train.reshape(batch_size,1,28,28))\n",
    "            #loss, grad, acc = softmax_loss(y_pred, y_train.argmax(axis=0))\n",
    "            loss, grad, acc = softmax(y_pred, y_train)\n",
    "            model1.backward(grad)\n",
    "            #model.update(0.5)\n",
    "            optimizer1.step()\n",
    "            pbar.set_postfix(loss=loss, acc=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle_batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 784)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.argmax(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 234/234 [03:26<00:00,  1.13it/s, acc=0.082, loss=2.3]\n"
     ]
    }
   ],
   "source": [
    "import dataloader\n",
    "from optimizer import Adam\n",
    "\n",
    "from loss import softmax_loss\n",
    "epochs = 1\n",
    "lr = 0.001\n",
    "batch_size = 256\n",
    "modell = LeNet5()\n",
    "optimizer = Adam(modell.get_params(), lr)\n",
    "\n",
    "pbar = tqdm(range(0, int(x.shape[0]/batch_size)), ncols=150)\n",
    "for i in pbar:\n",
    "    X_train, y_train = shuffle_batch(256)\n",
    "    y_pred = modell.forward(X_train.reshape(256,1,28,28))\n",
    "    loss, grad, acc = softmax_loss(y_pred, y_train.argmax(axis=0))\n",
    "    modell.backward(grad)\n",
    "    modell.update()\n",
    "    pbar.set_postfix(loss=loss, acc=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = train_images.shape #(60000,784),28*28 image\n",
    "    # data processing\n",
    "x, y = data_convert(train_images, train_labels, m, 10) # x:[m,n], y:[1,m]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
